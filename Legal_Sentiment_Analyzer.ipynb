{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "liQ9JgT0lQl5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "252cf9f9-e36b-4d01-d1b9-c51a10a9a8e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Sample:\n",
            "                                                text     label\n",
            "0  The law firm's efforts were acknowledged in th...  positive\n",
            "1  All stakeholders agreed to the settlement term...  positive\n",
            "2  The client complied with all regulatory requir...  positive\n",
            "3  The company was awarded compensation for the d...  positive\n",
            "4  The appeal was dismissed due to procedural err...  negative\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import libraries\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Step 2: Load datasets\n",
        "train_df = pd.read_csv('/content/legal_sentiment_train.csv')\n",
        "test_df = pd.read_csv('/content/legal_sentiment_test.csv')\n",
        "\n",
        "# Step 3: View dataset structure\n",
        "print(\"Training Set Sample:\")\n",
        "print(train_df.head())\n",
        "\n",
        "# Step 4: Preprocessing function\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    text = ' '.join(word for word in text.split() if word not in stop_words)  # Remove stopwords\n",
        "    return text\n",
        "\n",
        "# Step 5: Apply cleaning\n",
        "train_df['clean_text'] = train_df['text'].apply(clean_text)\n",
        "test_df['clean_text'] = test_df['text'].apply(clean_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Import TF-IDF Vectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Step 7: Initialize vectorizer\n",
        "tfidf = TfidfVectorizer(max_features=500)\n",
        "\n",
        "# Step 8: Fit and transform training and test data\n",
        "X_train = tfidf.fit_transform(train_df['clean_text']).toarray()\n",
        "X_test = tfidf.transform(test_df['clean_text']).toarray()\n",
        "\n",
        "# Step 9: Extract labels\n",
        "y_train = train_df['label']\n",
        "y_test = test_df['label']\n"
      ],
      "metadata": {
        "id": "DUs8lqrbzdp8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Import model and evaluation tools\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Step 11: Initialize and train the model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 12: Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Step 13: Evaluate model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nAccuracy Score:\")\n",
        "print(accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLOh5XV3zgpM",
        "outputId": "cdf7fb6f-5ea5-47cf-8c9e-c383a4411408"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[33  0  0]\n",
            " [ 0 30  0]\n",
            " [ 0  0 27]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       1.00      1.00      1.00        33\n",
            "     neutral       1.00      1.00      1.00        30\n",
            "    positive       1.00      1.00      1.00        27\n",
            "\n",
            "    accuracy                           1.00        90\n",
            "   macro avg       1.00      1.00      1.00        90\n",
            "weighted avg       1.00      1.00      1.00        90\n",
            "\n",
            "\n",
            "Accuracy Score:\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 14: Combine predictions with test data\n",
        "test_df['predicted_sentiment'] = y_pred\n",
        "\n",
        "# Step 15: Display representative examples from each class\n",
        "def show_summary_by_sentiment(sentiment):\n",
        "    subset = test_df[test_df['predicted_sentiment'] == sentiment]\n",
        "    print(f\"\\nðŸ”¹ Example {sentiment.upper()} Sentiment Documents:\\n\")\n",
        "    for i, row in subset.head(3).iterrows():\n",
        "        print(f\"Original: {row['text']}\")\n",
        "        print(f\"Cleaned: {row['clean_text']}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "# Step 16: Show 3 examples for each sentiment\n",
        "for sentiment in ['positive', 'negative', 'neutral']:\n",
        "    show_summary_by_sentiment(sentiment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvfBcU-A0P_7",
        "outputId": "6db9d8df-12b0-4490-a3d5-8e5501576de9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ Example POSITIVE Sentiment Documents:\n",
            "\n",
            "Original: The contract negotiation concluded successfully with mutual agreement.\n",
            "Cleaned: contract negotiation concluded successfully mutual agreement\n",
            "--------------------------------------------------------------------------------\n",
            "Original: All stakeholders agreed to the settlement terms in record time.\n",
            "Cleaned: stakeholders agreed settlement terms record time\n",
            "--------------------------------------------------------------------------------\n",
            "Original: The client complied with all regulatory requirements and was praised for diligence.\n",
            "Cleaned: client complied regulatory requirements praised diligence\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ðŸ”¹ Example NEGATIVE Sentiment Documents:\n",
            "\n",
            "Original: The defendant failed to provide any supporting documents despite multiple requests.\n",
            "Cleaned: defendant failed provide supporting documents despite multiple requests\n",
            "--------------------------------------------------------------------------------\n",
            "Original: The license was revoked following the audit findings.\n",
            "Cleaned: license revoked following audit findings\n",
            "--------------------------------------------------------------------------------\n",
            "Original: The defendant failed to provide any supporting documents despite multiple requests.\n",
            "Cleaned: defendant failed provide supporting documents despite multiple requests\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ðŸ”¹ Example NEUTRAL Sentiment Documents:\n",
            "\n",
            "Original: The team is awaiting further instructions from the legal advisor.\n",
            "Cleaned: team awaiting instructions legal advisor\n",
            "--------------------------------------------------------------------------------\n",
            "Original: The documents were scanned and archived digitally.\n",
            "Cleaned: documents scanned archived digitally\n",
            "--------------------------------------------------------------------------------\n",
            "Original: The team is awaiting further instructions from the legal advisor.\n",
            "Cleaned: team awaiting instructions legal advisor\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}